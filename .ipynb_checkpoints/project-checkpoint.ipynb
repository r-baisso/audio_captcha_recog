{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bem vindo ao Projeto de Reconhecimento de Audio ---\n",
      "\n",
      "Realizando Imports de Libs necessarias...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Bem vindo ao Projeto de Reconhecimento de Audio ---\")\n",
    "print(\"\\nRealizando Imports de Libs necessarias...\")\n",
    "\n",
    "import librosa\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "# import scipy.signal as sg\n",
    "# from scipy.fftpack import dct\n",
    "# from scipy.fftpack import fft\n",
    "# from scipy.fftpack import ifft\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculo do Chroma Energy Normalized Statistics (CENS) do sinal\n",
    "def calc_chroma(segmento, sr):\n",
    "    av = segmento.to_numpy(copy=True)\n",
    "    return np.mean(librosa.feature.chroma_cqt(y=av, sr=sr, n_chroma=24).T, axis=0)\n",
    "\n",
    "# calculo do Mel Spectrogram do sinal\n",
    "def calc_mel(segmento, sr):\n",
    "    av = segmento.to_numpy(copy=True)\n",
    "    return np.mean(librosa.feature.melspectrogram(av, sr=sr).T, axis=0)\n",
    "\n",
    "# calculo do MFCC medio para cada audio de entrada\n",
    "def calc_mfcc(segmento, sr):\n",
    "    av = segmento.to_numpy(copy=True)\n",
    "    return np.mean(librosa.feature.mfcc(y=av, sr=sr, n_mfcc=24).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza a extracao de features do sinal\n",
    "def feature_extraction(segmento, sr):\n",
    "    features = []\n",
    "    np.array(features)\n",
    "\n",
    "    features = np.append(features, calc_mfcc(segmento, sr))\n",
    "    features = np.append(features, calc_mel(segmento, sr))\n",
    "    features = np.append(features, calc_chroma(segmento, sr))\n",
    "    \"\"\"\n",
    "    features = np.append(features, calc_dct(segmento))\n",
    "    features = np.append(features, calc_fft(segmento))\n",
    "    \"\"\"\n",
    "    return features\n",
    "\n",
    "# divisao dos audios de entrada para separacao de cada letra\n",
    "def extract_intervals(signal, cut):\n",
    "    data_interval = []\n",
    "    interval = int(len(signal) // cut)\n",
    "    for i in range(0, cut) :\n",
    "        data_interval.append(pd.Series(signal[i*interval : (i+1)*interval]))\n",
    "    return data_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quebra o nome do arquivo em letras para categorizacao dos audios\n",
    "def get_labels(path_file):\n",
    "    path_file = re.sub(\"[ (1)]\", \"\", path_file)\n",
    "    return list(path_file[-8:-4])\n",
    "\n",
    "# faz a aquisicao do caminho de todos os arquivos na pasta path\n",
    "def get_files(path):\n",
    "    files = glob.glob(path + \"*.wav\")\n",
    "    return files\n",
    "\n",
    "def get_x_y(path, reduce=False):\n",
    "    files = get_files(path)\n",
    "    Xt = []\n",
    "    yt = []\n",
    "    segmentos = []\n",
    "    seed = random.randint(1, 1000)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(files)\n",
    "    # print(f\"Semente gerada: {seed}\\n\")\n",
    "    i = 0\n",
    "    for f in files:\n",
    "        data, sr = librosa.load(f, mono=True)\n",
    "        segmentos += extract_intervals(data, 4)\n",
    "        yt += get_labels(f)\n",
    "        # print(i)\n",
    "        if i > 30 and reduce:\n",
    "            break    \n",
    "        i += 1\n",
    "        \n",
    "\n",
    "    for segmento in segmentos:\n",
    "        Xt.append(feature_extraction(segmento, sr))\n",
    "    \n",
    "    return Xt,yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista os elementos (caracteres) unicos de um array\n",
    "def unique_values(l):\n",
    "    unique_list = []\n",
    "    for x in l: \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "\n",
    "\n",
    "# gera e imprime a matriz de confusao geral do modelo\n",
    "def print_conf_mtx(yt, y_pred, labels, classifier):\n",
    "    print(labels)\n",
    "    print()\n",
    "    cm = confusion_matrix(yt, y_pred, labels)\n",
    "    print(cm)\n",
    "    \"\"\"\n",
    "    print(\"\\nMatrizes de Confusao Individuais\")\n",
    "    print(multilabel_confusion_matrix(yt, y_pred))\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nPlotando Confusion Matrix geral usando o matplotlib...\")\n",
    "    print(\"Feche o arquivo de saída para continuar a execução\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the ' + classifier + ' classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.locator_params(nbins=len(labels))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('confusion_matrix_'+ classifier +'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'TREINAMENTO/'\n",
    "validation_path= 'VALIDACAO/'\n",
    "test_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando dados nas Pastas TREINAMENTO/ e VALIDACAO/ internas do projeto...\n",
      "\n",
      "Preparando DataSet para Treino\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBuscando dados nas Pastas {train_path} e {validation_path} internas do projeto...\")\n",
    "\n",
    "print(\"\\nPreparando DataSet para Treino\")\n",
    "X, y = get_x_y(train_path)\n",
    "# X, y = get_x_y(train_path, True)\n",
    "print(\"Preparando DataSet para Teste/Validacao\")\n",
    "Xt, yt = get_x_y(validation_path)\n",
    "# Xt, yt = get_x_y(validation_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInstanciando Modelo Random Forest (n_estimators = 500 e max_depth = 50)\")\n",
    "rfc = RandomForestClassifier(n_estimators = 500, max_depth = 50, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTreinando Modelo...\")\n",
    "rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Realizando Classificacao...\")\n",
    "y_rfc = rfc.predict(Xt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
